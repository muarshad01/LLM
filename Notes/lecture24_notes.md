```
Every effort moves you
```

***

* 15:00

* Embedding Size = 768

1. Token Embedding 
2. Positional Emdedding
3. Input Embedding = Token Embedding + Positioal Embedding
4. Droupout (We randomly turn off some elements of every uh every input embedding to zero. Benefits: a) Prevent overfitting; b) Improve generalization)
5. Transformer
  6. Layer Normaliztion
  7. Masked Multi-head Attention
  8. Dropout layer
  9. Layer Norm
  10. Feed forward neural network
  11. Dropout layer
  12. Shortcut connections
  13. Layer Normalization

***

* 35:00

* Fixal Step = Number of Tokens X 50,257

***
